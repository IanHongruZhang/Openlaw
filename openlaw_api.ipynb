{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 3.21\n",
    "## Update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from fake_useragent import UserAgent\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "from urllib.parse import quote\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from PIL import Image,ImageEnhance\n",
    "import hashlib\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract(html_list):\n",
    "    list_cases = list(map(lambda x:x.text,html_list))\n",
    "    list_cases_2 = list(map(lambda x:eval(x)[\"judgements\"],list_cases))\n",
    "    cases_3 = list(np.array(list_cases_2).flatten())\n",
    "    list_case = []\n",
    "    for index in range(0,10):\n",
    "        for item in cases_3[index]:\n",
    "            elem = item[\"judgement\"]\n",
    "            list_case.append(elem)\n",
    "    return list_case\n",
    "\n",
    "class openlaw():\n",
    "    def __init__(self):\n",
    "        self.AppKey = \"65d54678b0ec414baf31386fa799cbca\"\n",
    "        self.AppSecret = \"90a0af2cb7864ab28e160a89a9398436\"\n",
    "        self.Nonce = str(\"12sddrobc343fghasf5htl56\")\n",
    "        self.Curtime = str(int(time.time() * 1000))\n",
    "    \n",
    "    def openlaw_api_headers(self):\n",
    "        self.Combined = self.AppSecret + self.Nonce + self.Curtime\n",
    "        sha1 = hashlib.sha1(self.Combined.encode(\"utf-8\"))\n",
    "        self.CheckSum = sha1.hexdigest()\n",
    "        self.headers = {\"AppKey\":self.AppKey,\n",
    "                   \"Nonce\":self.Nonce,\n",
    "                   \"CurTime\":self.Curtime,\n",
    "                   \"CheckSum\":self.CheckSum}\n",
    "        return self.headers\n",
    "\n",
    "    def openlaw_api_search(self):\n",
    "        target = \"http://develop.openlaw.cn/judgement/search\"\n",
    "        keyword = input(\"请输入需要查询的案例关键词：\")\n",
    "        url = target + \"?keyword=\" + keyword\n",
    "        ### 以下为选填参数\n",
    "        \"\"\"\n",
    "        请求参数说明\n",
    "        参数\t参数说明\n",
    "        keyword\t搜索关键字\n",
    "        court\t法院名称\n",
    "        judgeDateYear\t判决年份\n",
    "        \"\"\"\n",
    "        switch = True\n",
    "        while switch == True:\n",
    "            court,year = None,None\n",
    "            paramater_none = input(\"是否需要其他设定参数（输入y/n）\")\n",
    "            if paramater_none == \"y\":\n",
    "                pass\n",
    "            else:\n",
    "                break\n",
    "            paramater = input(\"请输入还需要限定的参数\")\n",
    "            if paramater == \"法院名称\":\n",
    "                court = input(\"哪个法院？\")\n",
    "                url = url + \"&court=\" + str(court)\n",
    "            if paramater == \"判决年份\":\n",
    "                year = input(\"哪一年?\")\n",
    "                url = url + \"&judgeDateYear=\" + str(year)\n",
    "            paramater_none = input(\"还需要设定参数吗？（输入y/n）\")\n",
    "            if paramater_none == \"n\":\n",
    "                switch = False\n",
    "            else:\n",
    "                switch = True\n",
    "        headers = self.openlaw_api_headers()\n",
    "        html = requests.get(url,headers = headers)\n",
    "        return html\n",
    "    \n",
    "    def openlaw_api_search_v2(self,keyword):\n",
    "        #### 设定法院进行爬取\n",
    "        target = \"http://develop.openlaw.cn/judgement/search\"\n",
    "        list_urls = []\n",
    "        url = target + \"?keyword=\" + keyword\n",
    "        with open(\"courts.txt\",\"r\",encoding = \"utf-8\") as f:\n",
    "            court_list = eval(f.read())\n",
    "        #### 选择你需要的法院\n",
    "        for court in court_list[0:10]:\n",
    "            url_single = url + \"&court=\" + str(court)\n",
    "            list_urls.append(url_single)\n",
    "        headers = self.openlaw_api_headers()\n",
    "        html_list = list(map(lambda x:requests.get(x,headers = headers),list_urls))\n",
    "        list_case = extract(html_list)\n",
    "        return list_case\n",
    "        \n",
    "    def openlaw_api_court(self):\n",
    "        target = \"http://develop.openlaw.cn/judgement/court\"\n",
    "        dicts = {}\n",
    "        keycourt = input(\"请输入需要查询的法院：\")\n",
    "        headers = self.openlaw_api_headers()\n",
    "        dicts[\"court\"] = keycourt\n",
    "        html = requests.get(target,headers = headers,data = data)\n",
    "        return html\n",
    "        \n",
    "    def openlaw_api_analysis(self):\n",
    "        target = \"http://develop.openlaw.cn/analytic/judgement\"\n",
    "        dicts = {}\n",
    "        keycourt = input(\"请输入需要查询的关键字：\")\n",
    "        dicts[\"keyword\"] = keyword\n",
    "        html = requests.get(target,headers = headers,data = data)\n",
    "        return html\n",
    "        \n",
    "#o1 = openlaw()\n",
    "#html_list = o1.openlaw_api_search()\n",
    "#html_list = o1.openlaw_api_search_v2(\"合同\")\n",
    "#pd.DataFrame(html_list).to_excel(\"合同100_v2.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### PDF转化器 \n",
    "### 核心要点抽取，各类NLP抽取（使用HanLp）\n",
    "### 内容提取器(已经完成），法条统计器（已经完成）\n",
    "### 判决结果相似度分析器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"id\",\"selector\":\"username\"}\n  (Session info: chrome=71.0.3578.98)\n  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 6.1.7601 SP1 x86_64)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-e0baa8ea16c7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[0murl_bash\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"http://openlaw.cn/judgement/\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[0murls\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0murl_bash\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtable\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"id\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 53\u001b[1;33m \u001b[0mlist_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"http://openlaw.cn/login.jsp\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_account\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_password\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-7-e0baa8ea16c7>\u001b[0m in \u001b[0;36mrounds\u001b[1;34m(dicts, urls, login_entrance, login_account, login_password)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mrounds\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murls\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_entrance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_account\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_password\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdicts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_entrance\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_account\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlogin_password\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mlist_soup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-e0baa8ea16c7>\u001b[0m in \u001b[0;36mlogin\u001b[1;34m(dicts, login_entrance, account, password)\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mdriver\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwebdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mChrome\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"chromedriver.exe\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogin_entrance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0melem_account\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"username\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0melem_account\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend_keys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogin_account\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0melem_password\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"password\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element_by_id\u001b[1;34m(self, id_)\u001b[0m\n\u001b[0;32m    358\u001b[0m             \u001b[0melement\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'foo'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    359\u001b[0m         \"\"\"\n\u001b[1;32m--> 360\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    361\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements_by_id\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    976\u001b[0m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0;32m    977\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 978\u001b[1;33m             'value': value})['value']\n\u001b[0m\u001b[0;32m    979\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    980\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfind_elements\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mID\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    319\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    320\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 321\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    322\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    323\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    240\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 242\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    243\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    244\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_value_or_default\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdefault\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"id\",\"selector\":\"username\"}\n  (Session info: chrome=71.0.3578.98)\n  (Driver info: chromedriver=2.40.565498 (ea082db3280dd6843ebfb08a625e3eb905c4f5ab),platform=Windows NT 6.1.7601 SP1 x86_64)\n"
     ]
    }
   ],
   "source": [
    "## 强行爬取openlaw上的数据\n",
    "## 一个小时1000条左右\n",
    "from bs4 import BeautifulSoup\n",
    "import random\n",
    "\n",
    "def login(dicts,login_entrance,account,password):\n",
    "    driver = webdriver.Chrome(\"chromedriver.exe\")\n",
    "    driver.get(login_entrance)\n",
    "    elem_account = driver.find_element_by_id(\"username\")\n",
    "    elem_account.send_keys(login_account)\n",
    "    elem_password = driver.find_element_by_id(\"password\")\n",
    "    elem_password.send_keys(login_password)\n",
    "    elem_verification = driver.find_element_by_id(\"code\")\n",
    "    code = input(\"验证码是多少:\") # 手工打码\n",
    "    elem_verification.send_keys(code)\n",
    "    driver.find_element_by_id(\"submit\").click()\n",
    "    response = driver.page_source\n",
    "    html_soup = BeautifulSoup(response,'lxml')\n",
    "    return driver\n",
    "\n",
    "def rounds(dicts,urls,login_entrance,login_account,login_password):\n",
    "    driver = login(dicts,login_entrance,login_account,login_password)\n",
    "    print(driver)\n",
    "    list_soup = []\n",
    "    index = 0 \n",
    "    for url in urls[0:100]:\n",
    "        driver.get(url)\n",
    "        try:\n",
    "            element = WebDriverWait(driver,10).until(\n",
    "                EC.presence_of_element_located((By.CLASS_NAME,\"entry-title\"))\n",
    "            )\n",
    "            time.sleep(5)\n",
    "        except Exception as e:\n",
    "            time.sleep(5)\n",
    "            pass\n",
    "        html_soup = BeautifulSoup(driver.page_source,'lxml')\n",
    "        list_soup.append(html_soup)\n",
    "        index += 1\n",
    "        if index % 10 == 0:\n",
    "            time.sleep(10)\n",
    "        if index % 50 == 0:\n",
    "            time.sleep(50)\n",
    "        if index % 100 == 0:\n",
    "            pass\n",
    "    return list_soup\n",
    "\n",
    "dicts = {\"account\":[\"hongruzyj@hotmail.com\",\"hongruzyj@qq.com\"],\"password\":[\"945180zyj\",\"945180zyj\"]}\n",
    "login_account = dicts[\"account\"][0]\n",
    "login_password = dicts[\"password\"][0]\n",
    "table = pd.read_excel(\"合同100.xlsx\")\n",
    "url_bash = \"http://openlaw.cn/judgement/\"\n",
    "urls = list(map(lambda x:url_bash + x,table[\"id\"]))\n",
    "list_soup = rounds(dicts,urls,\"http://openlaw.cn/login.jsp\",login_account,login_password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'list_soup' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-059e49608898>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlist_soup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'list_soup' is not defined"
     ]
    }
   ],
   "source": [
    "len(list_soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### pdf转化器\n",
    "import os\n",
    "from pdfminer.converter import PDFPageAggregator\n",
    "from pdfminer.layout import LAParams\n",
    "from pdfminer.pdfparser import PDFParser, PDFDocument\n",
    "from pdfminer.pdfinterp import PDFResourceManager, PDFPageInterpreter\n",
    "from pdfminer.pdfdevice import PDFDevice\n",
    "\n",
    "def pdfreader(filename):\n",
    "    #获得文档对象,以二进制读方式打开\n",
    "    fp = open(filename, \"rb\")\n",
    "\n",
    "    #创建一个与文档关联的分析器\n",
    "    parser = PDFParser(fp)\n",
    "\n",
    "    #创建一个pdf文档的对象\n",
    "    doc = PDFDocument()\n",
    "\n",
    "    #连接解释器与文档对象\n",
    "    parser.set_document(doc)\n",
    "    doc.set_parser(parser)\n",
    "\n",
    "    #初始化文档,如果文档有密码，写与此。\n",
    "    doc.initialize(\"\")\n",
    "\n",
    "    #创建pdf资源管理器\n",
    "    resource = PDFResourceManager()\n",
    "\n",
    "    #参数分析器\n",
    "    laparam = LAParams()\n",
    "\n",
    "    #创建聚合器\n",
    "    device = PDFPageAggregator(resource, laparams=laparam)\n",
    "\n",
    "    #创建pdf页面解释器\n",
    "    interpreter = PDFPageInterpreter(resource, device)\n",
    "\n",
    "    #使用文档对象得到页面的集合\n",
    "    list_text,corpus = [],[]\n",
    "    for page in doc.get_pages():\n",
    "        #使用页面解释器读取\n",
    "        interpreter.process_page(page)\n",
    "        #使用聚合器来获得内容\n",
    "        layout = device.get_result()\n",
    "        for out in layout:\n",
    "            if hasattr(out, \"get_text\"):\n",
    "                line = out.get_text().strip(\"\\n \")\n",
    "                line_clean = re.sub(\"\\n\",\"\",line)\n",
    "                list_text.append(line_clean)\n",
    "    final_test = \"\".join([i for i in list_text if i != \"\"])\n",
    "    return final_test\n",
    "\n",
    "os.chdir(\"正当防卫的1000份文书\")\n",
    "file_list = os.listdir()\n",
    "corpus = list(map(pdfreader,file_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_corpus = []\n",
    "def get_soup_text(html_soup):\n",
    "    list_text_temp = []\n",
    "    try:\n",
    "        all_text_soup = html_soup.find_all(\"div\",class_ = \"part\")\n",
    "        for para in all_text_soup:\n",
    "            text = re.sub(\"\\n\",\"\",para.get_text())\n",
    "            text2 = re.sub(\" \",\"\",text)\n",
    "            text3 = re.sub(\" \",\"\",text2)\n",
    "            list_text_temp.append(text3)\n",
    "        return list_text_temp\n",
    "    except Exception as e:\n",
    "        return(\"None\")\n",
    "\n",
    "pd.DataFrame()\n",
    "list_corpus = list(map(get_soup_text,list_soup))\n",
    "list_corpus_text = list(map(lambda x:\"\".join(x),list_corpus))\n",
    "list_corpus_text\n",
    "table_corpus_with_id = pd.DataFrame([list_corpus_text,list(table['id'])]).T\n",
    "table_corpus_with_id.columns = [\"文本\",\"文本id\"]\n",
    "table_final_original = table_corpus_with_id[table_corpus_with_id[\"文本\"].str.len() > 50]\n",
    "table_final_original.index = range(len(table_final_original))\n",
    "table_final_original.to_excel(\"hetong_wenben.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 文本清理器\n",
    "def clean(corpus_none_n):\n",
    "    results = corpus_none_n\n",
    "    ### 原告中的三类可能\n",
    "    pattern_plaintiff = re.compile(r\"原告：([\\u4e00-\\u9fa5].*?)，\") # 原告第一类可能\n",
    "    pattern_plaintiff_2 = re.compile(r\"原告：([\\u4e00-\\u9fa5].*?)。\") # 原告第二类可能\n",
    "    pattern_plaintiff_3 = re.compile(r\"原告.*?，\") # 原告第三类可能\n",
    "\n",
    "    ### 被告中的三类可能\n",
    "    pattern_defender = re.compile(r\"被告：.*?，\")\n",
    "    pattern_defender_2 = re.compile(r\"被告：.*?。\")\n",
    "\n",
    "    ### 原告出生年龄\n",
    "    pattern_plaintiff_birthday = re.compile(r\"原告：.*\\d.*?出生，\")\n",
    "\n",
    "    ### 被告出生年龄\n",
    "    pattern_defender_birthday = re.compile(r\"被告：.*\\d.*?出生，\")\n",
    "\n",
    "    ### 立案时间\n",
    "    pattern_starttime = re.compile(r\"，本院于.*\\d.立案后，\")\n",
    "\n",
    "    ### 诉讼请求\n",
    "    pattern_claims = re.compile(r\"诉讼请求：.*?。\")\n",
    "    pattern_claims_2 = re.compile(r\"诉称，.*本院认为\")\n",
    "\n",
    "    ### 事实和理由\n",
    "    pattern_facts = re.compile(r\"事实和理由：.*。\")\n",
    "\n",
    "    ### 辩护事实\n",
    "    pattern_defence = re.compile(r\"辩称：.*\")\n",
    "    pattern_defence_2 = re.compile(r\"辩称，.*\")\n",
    "\n",
    "    ### 法院认定事实\n",
    "    pattern_court_fact_1 = re.compile(r\"认定事实如下：.*。本院\")\n",
    "    pattern_court_fact_2 = re.compile(r\"经审理查明：.*。本院\")\n",
    "    pattern_court_fact_3 = re.compile(r\"经审理查明，.*。本院\")\n",
    "\n",
    "    ### 法院对事实的判定\n",
    "    pattern_court_advise = re.compile(r\"本院认为.*\")\n",
    "\n",
    "    ### 法院的意见\n",
    "    pattern_court_attitude = re.compile(r\"综上所述.*?。\")\n",
    "\n",
    "    ### 法条\n",
    "    pattern_laws_1 = re.compile(r\"《.*?》.*?条\")\n",
    "    pattern_laws_2 = re.compile(r\"《.*?》.*?条，\")\n",
    "\n",
    "    ### 判决\n",
    "    pattern_judgement = re.compile(\"判决如下:.*。\") #需要使用去掉\\n的文档\n",
    "\n",
    "    ## 搜索原告\n",
    "    def find_plaintiffs(text,pattern1,pattern2,pattern3):\n",
    "        if re.search(pattern1,text):\n",
    "            piece = re.search(pattern1,text).group().strip(\":原告：，\")\n",
    "            return piece\n",
    "        elif re.search(pattern2,text):\n",
    "            piece = re.search(pattern2,text).group().strip(\":原告：，\")\n",
    "            return piece\n",
    "        elif re.search(pattern3,text):\n",
    "            piece = re.search(pattern3,text).group().strip(\":原告：，\")\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 搜索被告\n",
    "    def find_defender(text,pattern1,pattern2):\n",
    "        if re.search(pattern1,text):\n",
    "            piece = re.search(pattern1,text).group().strip(\"被告：\")\n",
    "            return piece\n",
    "        elif re.search(pattern2,text):\n",
    "            piece = re.search(pattern2,text).group().strip(\"被告：\")\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 搜索原告出生年龄\n",
    "    def find_plaintiffs_birthday(text,pattern):\n",
    "        if re.search(pattern,text):\n",
    "            piece = re.search(pattern,text).group().strip(\"，\")\n",
    "            text = re.sub(\"原告：.*，\",\"\",piece).strip(\"出生\")\n",
    "            return text\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 搜索被告出生年龄\n",
    "    def find_defenders_birthday(text,pattern):\n",
    "        if re.search(pattern,text):\n",
    "            piece = re.search(pattern,text).group().strip(\"，\")\n",
    "            text = re.sub(\"被告：.*，\",\"\",piece).strip(\"出生\")\n",
    "            return text\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 立案时间\n",
    "    def find_starttime(text,pattern):\n",
    "        if re.search(pattern,text):\n",
    "            piece = re.search(pattern,text).group().lstrip(\"，本院于\").rstrip(\"立案后，\")\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 事实和理由\n",
    "    def find_facts(text,pattern):\n",
    "        if re.search(pattern,text):\n",
    "            piece = re.search(pattern,text).group()\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 被告辩称\n",
    "    def find_defenders_words(text,pattern1,pattern2):\n",
    "        if re.search(pattern1,text):\n",
    "            piece = re.search(pattern1,text).group()\n",
    "            return piece\n",
    "        elif re.search(pattern2,text):\n",
    "            piece = re.search(pattern2,text).group()\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 法院认定事实\n",
    "    def find_court_facts(text,pattern1,pattern2,pattern3):\n",
    "        if re.search(pattern1,text):\n",
    "            piece = re.search(pattern1,text).group().rstrip(\"本院\")\n",
    "            return piece\n",
    "        elif re.search(pattern2,text):\n",
    "            piece = re.search(pattern2,text).group().rstrip(\"本院\")\n",
    "            return piece\n",
    "        elif re.search(pattern3,text):\n",
    "            piece = re.search(pattern3,text).group().rstrip(\"本院\")\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 查找法条\n",
    "    def find_laws(text,pattern1,pattern2):\n",
    "        if re.search(pattern1,text):\n",
    "            pieces = re.findall(pattern1,text)\n",
    "            short_pieces_1 = list(filter(lambda x:len(x) < 50,pieces))\n",
    "            pieces = re.findall(pattern2,text)\n",
    "            short_pieces_2 = list(filter(lambda x:len(x) < 50,pieces))\n",
    "            short_pieces = short_pieces_1 + short_pieces_2\n",
    "            return short_pieces\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    ## 大块文字专用\n",
    "    def find_claims_or_blocks(text,pattern):\n",
    "        if re.search(pattern,text):\n",
    "            piece = re.search(pattern,text).group()\n",
    "            return piece\n",
    "        else:\n",
    "            return None\n",
    "    \n",
    "    ## 原告诉求\n",
    "    def find_claims(text,pattern1,pattern2):\n",
    "        if re.search(pattern1,text):\n",
    "            piece = re.search(pattern1,text).group()\n",
    "            return piece\n",
    "        elif re.search(pattern2,text):\n",
    "            piece = re.search(pattern2,text).group()\n",
    "            return piece\n",
    "        \n",
    "    ## 重复pattern，构造pattern list\n",
    "    def repeat_pattern(pattern):\n",
    "        pattern_lists = len(list(results)) * [pattern]\n",
    "        return pattern_lists\n",
    "\n",
    "    list_piece_t,list_corpus = [],[] \n",
    "\n",
    "    ### 是否这里可以改成(**kwargs)\n",
    "    ### 原告\n",
    "\n",
    "    plaintiffs = list(map(find_plaintiffs,corpus_none_n,repeat_pattern(pattern_plaintiff),\n",
    "                          repeat_pattern(pattern_plaintiff_2),repeat_pattern(pattern_plaintiff_3)))\n",
    "\n",
    "    ### 被告\n",
    "    defenders = list(map(find_defender,corpus_none_n,repeat_pattern(pattern_defender),\n",
    "                        repeat_pattern(pattern_defender_2)))\n",
    "    \n",
    "    ### 原告出生年龄\n",
    "    plaintiffs_birthday = list(map(find_plaintiffs_birthday,corpus_none_n,repeat_pattern(pattern_plaintiff_birthday)))\n",
    "\n",
    "    ###被告出生年龄\n",
    "    defenders_birthday = list(map(find_defenders_birthday,corpus_none_n,repeat_pattern(pattern_defender_birthday)))\n",
    "\n",
    "    ### 立案时间\n",
    "    starttimes = list(map(find_starttime,corpus_none_n,repeat_pattern(pattern_starttime)))\n",
    "\n",
    "    ### 诉讼请求\n",
    "    claims = list(map(find_claims,corpus_none_n,repeat_pattern(pattern_claims),repeat_pattern(pattern_claims_2)))\n",
    "\n",
    "    ### 事实与理由\n",
    "    facts = list(map(find_claims_or_blocks,corpus_none_n,repeat_pattern(pattern_facts)))\n",
    "\n",
    "    ### 被告辩称\n",
    "    \n",
    "    defences = list(map(find_defender,corpus_none_n,repeat_pattern(pattern_defence),\n",
    "                        repeat_pattern(pattern_defence_2)))\n",
    "    \n",
    "    ### 法院认定事实\n",
    "    court_facts = list(map(find_court_facts,corpus_none_n,repeat_pattern(pattern_court_fact_1),\n",
    "                          repeat_pattern(pattern_court_fact_2),repeat_pattern(pattern_court_fact_3)))\n",
    "\n",
    "    ### 法院对事实的判定\n",
    "    advises = list(map(find_claims_or_blocks,corpus_none_n,repeat_pattern(pattern_court_advise)))\n",
    "\n",
    "    ### 法院的态度\n",
    "    attitudes = list(map(find_claims_or_blocks,corpus_none_n,repeat_pattern(pattern_court_attitude)))\n",
    "\n",
    "    ### 判决\n",
    "    judgement = list(map(find_claims_or_blocks,corpus_none_n,repeat_pattern(pattern_judgement)))\n",
    "\n",
    "    ### 法条\n",
    "    laws = list(map(find_laws,corpus_none_n,repeat_pattern(pattern_laws_1),\n",
    "                        repeat_pattern(pattern_laws_2)))\n",
    "    table_caipanwenshu = pd.DataFrame([plaintiffs,defenders,plaintiffs_birthday,defenders_birthday,\n",
    "                                   starttimes,claims,facts,defences,court_facts,advises,attitudes,judgement,laws]).T\n",
    "    table_caipanwenshu.columns = [\"原告\",\"被告\",\"原告出生时间\",\"被告出生时间\",\"立案时间\",\"原告诉讼请求\",\n",
    "                              \"原告事实与理由\",\"被告辩称\",\"法院认定事实\",\"法院认为\",\"法院意见\",\"法院判决\",\"法条\"]\n",
    "    return table_caipanwenshu\n",
    "### 判决后：如不服本判决，可以在判决书送达之日起十五日内，向本院递交上诉状，并按照对方当事人或者代表人的人数提出副本，上诉于北京市第一中级人民法院。\n",
    "### 一审，二审要在裁判文书爬虫是就得确定好\n",
    "### 案由，案件类型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_none_columns(table):\n",
    "    index_exist,index_none = 0,0\n",
    "    list_keep = []\n",
    "    for column in list(table.columns):\n",
    "        for item in table[column]:\n",
    "            if item != None:\n",
    "                index_exist += 1\n",
    "            else:\n",
    "                index_none += 1\n",
    "        ratio = float(index_none) / (float(index_exist) + 1.0) # 剃掉很多都是None的行\n",
    "        if ratio<= 10:\n",
    "            list_keep.append(table[column])\n",
    "        else:\n",
    "            pass\n",
    "        index_exist = 0\n",
    "        index_none = 0\n",
    "    return pd.DataFrame(list_keep).T\n",
    "\n",
    "table = clean(corpus)\n",
    "table_final = table.drop([\"被告\",\"原告出生时间\",\"被告出生时间\",\"立案时间\",\"原告诉讼请求\",\"原告事实与理由\"],axis = 1)\n",
    "table_final\n",
    "#for item in table.columns:\n",
    "    #table[item]\n",
    "\n",
    "#table_final_original[\"文本id\"]\n",
    "#table.join(table_final_original[\"文本id\"])\n",
    "#table2 = drop_none_columns(table)\n",
    "#table3 = table2.join(table_final_original[\"文本id\"])\n",
    "#pd.merge(table3,table_hetong,left_on = \"文本id\",right_on = \"id\",how = \"left\").to_excel(\"final.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "import jieba\n",
    "import codecs, sys\n",
    "\n",
    "table_judgements = table_final[\"法院判决\"].dropna()\n",
    "table_segments_list = list(map(lambda x:jieba.lcut(x),table_judgements))\n",
    "stopwords = list(map(lambda x:x.strip(\"\\n\"),codecs.open('stopwords.txt', 'r', 'utf-8').readlines()))\n",
    "stopwords_clean = list(map(lambda x:x.strip(\"\\r\"),stopwords))\n",
    "def clean(single_para):\n",
    "    list_clean = set(single_para).difference(set(stopwords_clean))\n",
    "    return list_clean\n",
    "\n",
    "list_clean = list(map(clean,table_segments_list))\n",
    "texts = list_clean\n",
    "# load id->word mapping (the dictionary)\n",
    "dictionary = corpora.Dictionary(list_clean)\n",
    "# word must appear >10 times, and no more than 40% documents\n",
    "# dictionary.filter_extremes(no_below=40, no_above=0.1)\n",
    "# save dictionary\n",
    "dictionary.save('dict_v1.dict')\n",
    "\n",
    "# load corpus\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# initialize a model\n",
    "tfidf = models.TfidfModel(corpus)\n",
    "\n",
    "# use the model to transform vectors, apply a transformation to a whole corpus\n",
    "corpus_tfidf = tfidf[corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "index = similarities.MatrixSimilarity(corpus_tfidf)\n",
    "sims = index[corpus[10]]\n",
    "similarity = list(sims)\n",
    "np.argmax(similarity)\n",
    "max_similarities = np.array(similarity).argsort()[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_judgements[10]\n",
    "table_judgements[607]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### 统计法条数量\n",
    "def count_laws(table):\n",
    "    list_fatiao_corpus = []\n",
    "    fatiao2d = list(table[\"法条\"])\n",
    "    for case in fatiao2d:\n",
    "        if case != None:\n",
    "            case_unrepeated = list(set(case))\n",
    "            for law in case_unrepeated:\n",
    "                list_fatiao_corpus.append(law)\n",
    "    table_laws = pd.DataFrame([dict(Counter(list_fatiao_corpus))]).T\n",
    "    table_laws.columns = [\"数量\"]\n",
    "    table_laws_ascending = table_laws.sort_values(\"数量\",ascending = False)\n",
    "    return table_laws_ascending\n",
    "count_laws(table).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "参数\t参数说明\n",
    "keyword\t搜索关键字\n",
    "court\t法院名称\n",
    "courtId\t法院id\n",
    "docType\t文书类型\n",
    "lawFirmId\t律所id\n",
    "lawFirmName\t律所名称\n",
    "lawyer\t律师名称\n",
    "lawyerId\t律师id\n",
    "caseNo\t案号\n",
    "litigant\t当事人\n",
    "plaintiff\t原告\n",
    "defendant\t被告\n",
    "thirdParty\t第三人\n",
    "judgeDateYear\t判决年份\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "cookie = \"s_token=1772f16933714319bc43c12f8efbfeba;\"\n",
    "         \"c_token=f1y313371tf16933714319bc43c12f8efbfebay714319bc;\"\n",
    "         \"Hm_lvt_a105f5952beb915ade56722dc85adf05=1548147169,1548147172,1548147188,1548147191;\"\n",
    "         \"SESSION=OTk3ODY5OTQtZDNmOC00MDExLWIwM2YtODhkYTFmZGNhMzdj;\" \n",
    "         \"Hm_lpvt_a105f5952beb915ade56722dc85adf05=1548204430\"\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "cookie = \"s_token=901674c48bfd4c2bad98b6209f84b953; c_token=74tcw8bfdy74c48bfd4c2bad98b6209f84b9533fd4c2bad; Hm_lvt_a105f5952beb915ade56722dc85adf05=1548147169,1548147172,1548147188,1548147191; SESSION=Mzk4ZjBhYzktYjU5NC00NWY0LTkyMTItZjFhMzY4M2ZlMjhk; Hm_lpvt_a105f5952beb915ade56722dc85adf05=1548207935\"\n",
    "table = pd.read_excel(\"重婚100.xlsx\")\n",
    "list_url = list(map(lambda x:\"http://openlaw.cn/judgement/\" + x,table[\"id\"]))\n",
    "options = webdriver.ChromeOptions()\n",
    "options.add_argument('Cookie=\"s_token=520d79ec8a224b4fa09844d4b84703e0; c_token=79ubx8a22e79ec8a224b4fa09844d4b84703e0j224b4fa0; Hm_lvt_a105f5952beb915ade56722dc85adf05=1548147169,1548147172,1548147188,1548147191; SESSION=Mzk4ZjBhYzktYjU5NC00NWY0LTkyMTItZjFhMzY4M2ZlMjhk; Hm_lpvt_a105f5952beb915ade56722dc85adf05=1548209820\"')\n",
    "driver = webdriver.Chrome(\"chromedriver.exe\",chrome_options=options)\n",
    "driver.get(\"http://openlaw.cn/judgement/1993eaec7b0543b7a2f9853f24f4b13b\")\n",
    "print(driver.get_cookies())\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "cookie = \"Hm_lvt_a105f5952beb915ade56722dc85adf05=1548147169,1548147172,1548147188,1548147191; SESSION=MGU0Y2NhMDctYzUzMC00MTA3LWJhMjYtYjhjODBlOGVjMGU2; Hm_lpvt_a105f5952beb915ade56722dc85adf05=1548210517\"\n",
    "headers = {\"User-Agent\":ua.random,\n",
    "           \"Accept\":\"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8\",\n",
    "           \"Accept-Encoding\":\"gzip, deflate\",\n",
    "           \"Accept-Language\":\"zh-CN,zh;q=0.9\",\n",
    "           \"Cache-Control\":\"max-age=0\",\n",
    "           \"Host\":\"openlaw.cn\",\n",
    "           \"Upgrade-Insecure-Requests\":\"1\",\n",
    "           \"Cookie\":cookie}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "打码技术研究\n",
    "import urllib.request\n",
    "import re\n",
    "import tesserocr\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "checkcode_src = BeautifulSoup(response,'lxml').find(\"img\",{\"id\":\"kaptcha\"})[\"src\"]\n",
    "checkcode_url = \"http://openlaw.cn\" + checkcode_src\n",
    "urllib.request.urlretrieve(checkcode_url,\"checkcode.jpg\")\n",
    "image = Image.open(\"checkcode.jpg\")\n",
    "image.show()\n",
    "result = tesserocr.image_to_text(image)\n",
    "print(result)\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "Normal_Request\n",
    "def normal_request():\n",
    "    list_responses = []\n",
    "    for url in url_total[1:2]:\n",
    "        try:\n",
    "            response = requests.get(url,headers = headers)\n",
    "            if response.status_code == 200:\n",
    "                list_responses.append(response.text)\n",
    "            else:\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            pass\n",
    "\"\"\"\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
